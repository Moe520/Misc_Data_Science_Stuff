{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# twitter sends its data as a json\n",
        "import json\n",
        "# we will convert the json data into a csv\n",
        "import csv"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy's np.nan helps us deal with missing values (and there is a TON of missing values in tweets) \n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the working directory to where the json is located. The output csv will be in this same directory\n",
        "# Windows users: remember to double-up the backward slashes!\n",
        "import os\n",
        "os.chdir(\"C:\\\\Users\\\\PC\\\\Documents\\\\GitHub\\\\Moe_Antar\\\\Json Parsing Script\")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# the fix_encoding function from the FTFY package takes care of weird characters in tweets\n",
        "import ftfy"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# adapted from vincent tatan's youtube guide for NLP\n",
        "def chwrd(word, text):\n",
        "    try:\n",
        "        text = text.lower()\n",
        "        match = re.search(word, text)\n",
        "        if match:\n",
        "            return True\n",
        "        return False\n",
        "    except AttributeError:\n",
        "        return False\n",
        "\n",
        "# Testing out word_in_text to find a certain word in a text\n",
        "print(chwrd('hello','Hi there maybe, I would say hello instead'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "x = \"hello its me\"\n",
        "if chwrd(\"him\",x):\n",
        "    print(\"yes\")\n",
        "else:\n",
        "    print(\"no\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def check_multiple(words,text):\n",
        "    result = False\n",
        "    for i in range(len(words)):\n",
        "        if chwrd(words[i],text) == True:\n",
        "            result = True\n",
        "        else:\n",
        "            pass\n",
        "    return result"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "x = \"I like Walmart\"\n",
        "y = \"I like Bestbuy\"\n",
        "z = \"I like ice cream\"\n",
        "\ncheck_multiple([\"walmart\",\"bestbuy\"],x)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "check_multiple([\"walmart\",\"bestbuy\"],y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "check_multiple([\"walmart\",\"bestbuy\"],z)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_json_file(json_file_name ,competitor_list, supplier_list , bestbuy_list ,output_file_name = \"parsed_tweets.csv\", stop_at = 1000000000, ):\n",
        "    # Create an empty csv file that we will append to\n",
        "    # Create a header row for it\n",
        "    print(\"Initalizing Output File:  %s\"%output_file_name)\n",
        "    print(\"Generating Header Row\")\n",
        "    with open('%s'%output_file_name,'w') as f:\n",
        "        f.write('id,text,created_at,language,retweet_count,screen_name,country,user_followers_count,time_zone,user_account_location,longitude,lattitude,bestbuy,competitor,supplier,no_category\\n') #  Column headers and a trailing new line . MAKE SURE the /n is attached to the last field: eg. text/n\n",
        "    \n",
        "    \n",
        "    tweet_counter = 0\n",
        "    \n",
        "    for i in open(json_file_name): \n",
        "        \n",
        "        if tweet_counter > stop_at:\n",
        "            break\n",
        "             \n",
        "        try:\n",
        "            # Put the data from the current tweet into a list\n",
        "            # Parse the current tweet\n",
        "            current_tweet = json.loads(i)\n",
        "            \n",
        "            ##################################################################\n",
        "            \n",
        "            ## Elements that are 1 level deep ## ##\n",
        "            \n",
        "            # Get the id or insert a nan if not found\n",
        "            if 'id' in current_tweet:\n",
        "                id = current_tweet['id']\n",
        "            else:\n",
        "                id= np.nan\n",
        "             \n",
        "            # Get text or insert nan\n",
        "            \n",
        "            if 'text' in current_tweet:\n",
        "                text = current_tweet['text']\n",
        "                \n",
        "                # the fix_encoding function from the FTFY package takes care of weird characters\n",
        "                text = ftfy.fix_encoding(text)\n",
        "            else:\n",
        "                text = np.nan\n",
        "                \n",
        "                \n",
        "            # Get created_at or insert nan\n",
        "            \n",
        "            if 'created_at' in current_tweet:\n",
        "                created_at = current_tweet['created_at']\n",
        "                \n",
        "            else:\n",
        "                created_at = np.nan\n",
        "            \n",
        "           # Get language or insert nan\n",
        "           \n",
        "            if 'lang' in current_tweet:\n",
        "                language = current_tweet['lang']\n",
        "     \n",
        "            else:\n",
        "                language = np.nan     \n",
        "            \n",
        "            \n",
        "            \n",
        "            # get retweet count or insert nan\n",
        "                \n",
        "            if 'retweet_count' in current_tweet:\n",
        "                retweet_count = current_tweet['retweet_count']\n",
        "            else:\n",
        "                retweet_count = np.nan\n",
        "                \n",
        "          ## Elements that are 2 levels deep ### ###\n",
        "            \n",
        "            # For elements that are 2 layers deep use != None when searching because javascript uses None as its null operator    \n",
        "            # get screen name or insert nan\n",
        "            \n",
        "            if 'user' in current_tweet and 'screen_name' in current_tweet['user']:\n",
        "                screen_name = current_tweet['user']['screen_name']\n",
        "            else:\n",
        "                screen_name = np.nan\n",
        "                \n",
        "            # get country or insert nan\n",
        "\n",
        "            if current_tweet['place'] != None and current_tweet['place']['country'] != None:\n",
        "                country = current_tweet['place']['country']\n",
        "            else:\n",
        "                country = np.nan\n",
        "            \n",
        "            # get the author's follower count or nan\n",
        "\n",
        "            if current_tweet['user'] != None and current_tweet['user']['followers_count'] != None:\n",
        "                followers_count = current_tweet['user']['followers_count']\n",
        "            else:\n",
        "                followers_count = np.nan\n",
        "            \n",
        "            \n",
        "            # get the timezone or nan\n",
        "            if current_tweet['user'] != None and current_tweet['user']['time_zone'] != None:\n",
        "                time_zone = current_tweet['user']['time_zone']\n",
        "            else:\n",
        "                time_zone = np.nan\n",
        "                \n",
        "            # get the account location or insert nan\n",
        "            \n",
        "            if current_tweet['user'] != None and current_tweet['user']['location'] != None:\n",
        "                account_location = current_tweet['user']['location']\n",
        "                account_location = ftfy.fix_encoding(account_location)\n",
        "            else:\n",
        "                account_location = np.nan\n",
        "                \n",
        "            ###### Elements that are 3 levels deep ##################################\n",
        "            \n",
        "            if current_tweet['coordinates'] != None and current_tweet['coordinates']['coordinates'] != None and len(current_tweet['coordinates']['coordinates'])==2:\n",
        "                longitude = current_tweet['coordinates']['coordinates'][0]\n",
        "            else:\n",
        "                longitude = np.nan\n",
        "                \n",
        "            if current_tweet['coordinates'] != None and current_tweet['coordinates']['coordinates'] != None and len(current_tweet['coordinates']['coordinates'])==2:\n",
        "                lattitude = current_tweet['coordinates']['coordinates'][1]\n",
        "            else:\n",
        "                lattitude = np.nan\n",
        "                \n",
        "            ########### Categorization Variables ###############################################\n",
        "            \n",
        "            ## True if the word bestbuy is there, False otherwise ###################\n",
        "            if text != np.nan:\n",
        "                if check_multiple(bestbuy_list,text):\n",
        "                    bestbuy = True\n",
        "                else:\n",
        "                    bestbuy = False\n",
        "            else: \n",
        "                bestbuy = False\n",
        "                    \n",
        "            ### True if the name of a competitor is in there , False otherwise ################\n",
        "\n",
        "            if text != np.nan:\n",
        "                if check_multiple(competitor_list,text):\n",
        "                    competitor = True\n",
        "                else:\n",
        "                    competitor = False\n",
        "            else:\n",
        "                competitor = False\n",
        "\n",
        "            ## True if the name of a supplier is in there , False otherwise ################\n",
        "\n",
        "            if text != np.nan:\n",
        "                if check_multiple(supplier_list,text):\n",
        "                    supplier = True\n",
        "                else:\n",
        "                    supplier = False\n",
        "            else:\n",
        "                supplier = False\n",
        "                \n",
        "            ## True if no names of suppliers, competitors, or bestbuy were found\n",
        "            \n",
        "            if text != np.nan:\n",
        "                if bestbuy == False and competitor == False and supplier == False:\n",
        "                    no_category = True\n",
        "                else:\n",
        "                    no_category = False\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "                    \n",
        "            ######################################################################################################\n",
        "            # Assemble the row\n",
        "            cleaned_current_tweet = [id,text,created_at,language, retweet_count, screen_name, country, followers_count,time_zone,account_location,longitude,lattitude,bestbuy,competitor,supplier,no_category]\n",
        "        \n",
        "            # Increment the Tweet Counter\n",
        "            tweet_counter = tweet_counter + 1\n",
        "            \n",
        "            # Give the user a progress update\n",
        "            if tweet_counter % 10000 == 0:\n",
        "                print(\" %d Tweets Parsed so far.....\" %tweet_counter)\n",
        "            \n",
        "            #append the current tweet as a row to the csv\n",
        "            with open('%s'%output_file_name,'a',newline='') as f:\n",
        "                writer=csv.writer(f)\n",
        "                writer.writerow(cleaned_current_tweet)\n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    print(\" \")\n",
        "    print(\" Parsing Complete:    %d Tweets Parsed \" %tweet_counter)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "my_bestbuy_list= [\"best buy\",\"bestbuy\",\"best-buy\",\"geek squad\",\"geeksquad\",\"bbycanada\"]\n",
        "my_competitor_list= [\"walmart\",\"wal-mart\",\"wal mart\",\"amazon\",\"prime\",\"visions\",\"ncix\",\"londondrugs\",\n",
        "                                   \"london drugs\",\"gamestop\",\"game stop\",\"ebgames\",\"eb games\"]\n",
        "my_supplier_list=[\"samsung\",\"galaxy\",\"smarthub\",\"apple\",\"mac\",\"iphone\",\"ipad\",\n",
        "                                \"tim_cook\",\"appstore\",\"microsoft\",\"xbox\",\"surface\",\n",
        "                                \"sony\",\"ps4\",\"playstation\",\"bravia\",\"nintendo\",\"nes\",\"hp\",\n",
        "                                \"hewlett\",\"coffeecoaching\",\"lg\",\"lifesgood\",\"g6\",\"canon\",\"dslr\",\"philips\",\"cleanteeth\",\n",
        "                                \"google\",\"pixel\",\"android\",\"nexus\",\"chromecast\",\"sharp\"]"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "my_bestbuy_list"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": [
              "['best buy', 'bestbuy', 'best-buy', 'geek squad', 'geeksquad', 'bbycanada']"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "my_competitor_list"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": [
              "['walmart',\n",
              " 'wal-mart',\n",
              " 'wal mart',\n",
              " 'amazon',\n",
              " 'prime',\n",
              " 'visions',\n",
              " 'ncix',\n",
              " 'londondrugs',\n",
              " 'london drugs',\n",
              " 'gamestop',\n",
              " 'game stop',\n",
              " 'ebgames',\n",
              " 'eb games']"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "my_supplier_list"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": [
              "['samsung',\n",
              " 'galaxy',\n",
              " 'smarthub',\n",
              " 'apple',\n",
              " 'mac',\n",
              " 'iphone',\n",
              " 'ipad',\n",
              " 'tim_cook',\n",
              " 'appstore',\n",
              " 'microsoft',\n",
              " 'xbox',\n",
              " 'surface',\n",
              " 'sony',\n",
              " 'ps4',\n",
              " 'playstation',\n",
              " 'bravia',\n",
              " 'nintendo',\n",
              " 'nes',\n",
              " 'hp',\n",
              " 'hewlett',\n",
              " 'coffeecoaching',\n",
              " 'lg',\n",
              " 'lifesgood',\n",
              " 'g6',\n",
              " 'canon',\n",
              " 'dslr',\n",
              " 'philips',\n",
              " 'cleanteeth',\n",
              " 'google',\n",
              " 'pixel',\n",
              " 'android',\n",
              " 'nexus',\n",
              " 'chromecast',\n",
              " 'sharp']"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# This calls the parsing function. Set the parameters as follows:\n",
        "## json_file_name = the name of the json file you want to parse eg \"industry.json\"\n",
        "## bestbuy_list = a python list containing the bestbuy keywords (e.g [\"bestbuy\",\"best-buy\"]\n",
        "## competitor_list = same as above but for competitor keywords\n",
        "## supplier_list = same as above but for suppliers\n",
        "## output_file_name = what the csv that is output should be called eg \"my_output.csv\"\n",
        "## stop at = how many tweets to parse e.g 1000000 (if you leave it blank it will parse up to a billion tweets)\n",
        "\n",
        "stream_json_file(json_file_name=\"industry_wk_2.json\",\n",
        "                 bestbuy_list= my_bestbuy_list,\n",
        "                 competitor_list= my_competitor_list,\n",
        "                 supplier_list= my_supplier_list,\n",
        "                 output_file_name = \"clean_wk2_full.csv\",\n",
        "                 stop_at=1000000000)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initalizing Output File:  clean_wk2_full.csv\n",
            "Generating Header Row\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 10000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 30000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 40000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 50000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 60000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 70000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 80000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 90000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 110000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 120000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 130000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 140000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 150000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 160000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 170000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 180000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 190000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 200000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 210000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 220000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 230000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 240000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 250000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 260000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 270000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 280000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 290000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 300000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 310000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 320000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 330000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 340000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 350000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 360000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 370000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 380000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 390000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 400000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 410000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 420000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 430000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 440000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 450000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 460000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 470000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 480000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 490000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 500000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 510000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 520000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 530000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 540000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 550000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 560000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 570000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 580000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 590000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 600000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 610000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 620000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 630000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 640000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 650000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 660000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 670000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 680000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 690000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 700000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 710000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 720000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 730000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 740000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 750000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 760000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 770000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 780000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 790000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 800000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 810000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 820000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 830000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 840000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 850000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 860000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 870000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 880000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 890000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 900000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 910000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 920000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 930000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 940000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 950000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 960000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 970000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 980000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 990000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1000000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1010000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1020000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1030000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1040000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1050000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1060000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1070000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1080000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1090000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1100000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1110000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1120000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1130000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1140000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1150000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1160000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1170000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1180000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1190000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1200000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1210000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1220000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1230000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1240000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1250000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1260000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1270000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1280000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1290000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1300000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1310000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1320000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1330000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1340000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1350000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1360000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1370000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1380000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1390000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1400000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1410000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1420000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1430000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1440000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1450000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1460000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1470000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1480000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1490000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1500000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1510000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1520000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1530000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1540000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1550000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1560000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1570000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1580000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1590000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1600000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1610000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1620000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1630000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1640000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1650000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1660000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1670000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1680000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1690000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1700000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1710000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1720000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1730000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1740000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1750000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1760000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1770000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1780000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1790000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1800000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1810000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1820000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1830000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1840000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1850000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1860000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1870000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1880000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1890000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1900000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1910000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1920000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1930000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1940000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1950000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1960000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1970000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1980000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1990000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2000000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2010000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2020000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2030000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2040000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2050000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2060000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2070000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2080000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2090000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2100000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2110000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2120000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2130000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2140000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2150000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2160000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2170000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2180000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2190000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2200000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2210000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2220000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2230000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2240000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2250000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2260000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2270000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2280000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2290000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2300000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2310000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2320000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2330000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2340000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2350000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2360000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2370000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2380000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2390000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2400000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2410000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2420000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2430000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2440000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2450000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2460000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2470000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2480000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2490000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2500000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2510000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2520000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2530000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2540000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2550000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2560000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2570000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2580000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2590000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2600000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2610000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2620000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2630000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2640000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2650000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2660000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2670000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2680000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2690000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2700000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2710000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2720000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2730000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2740000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2750000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2760000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2770000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2780000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2790000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2800000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2810000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2820000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2830000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2840000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2850000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2860000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2870000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2880000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2890000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2900000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2910000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2920000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2930000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2940000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2950000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2960000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2970000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2980000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2990000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3000000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3010000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3020000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3030000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3040000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3050000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3060000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3070000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3080000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3090000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3100000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3110000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3120000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3130000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3140000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3150000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3160000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3170000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3180000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3190000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3200000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3210000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3220000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3230000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3240000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3250000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3260000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3270000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3280000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3290000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3300000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3310000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3320000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3330000 Tweets Parsed so far.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " Parsing Complete:    3338827 Tweets Parsed \n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "nteract": {
      "version": "0.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}